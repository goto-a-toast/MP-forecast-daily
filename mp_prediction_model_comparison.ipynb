{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPï¼ˆé™ç•Œåˆ©ç›Šï¼‰äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒå®Ÿé¨“\n",
    "\n",
    "è¤‡æ•°ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã—ã¦ã€æœ€ã‚‚ç²¾åº¦ã®é«˜ã„ãƒ¢ãƒ‡ãƒ«ã‚’ç‰¹å®šã—ã¾ã™ã€‚\n",
    "\n",
    "## æ¯”è¼ƒã™ã‚‹ãƒ¢ãƒ‡ãƒ«\n",
    "1. **ç·šå½¢å›å¸°** (Linear Regression)\n",
    "2. **Ridgeå›å¸°** (L2æ­£å‰‡åŒ–)\n",
    "3. **Lassoå›å¸°** (L1æ­£å‰‡åŒ–)\n",
    "4. **ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ** (Random Forest)\n",
    "5. **å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°** (Gradient Boosting)\n",
    "6. **XGBoost**\n",
    "7. **LightGBM**\n",
    "8. **Prophet**ï¼ˆæ™‚ç³»åˆ—ç‰¹åŒ–ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required libraries\n!pip install xgboost lightgbm prophet -q"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split, TimeSeriesSplit, cross_val_score\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\nfrom sklearn.preprocessing import StandardScaler\n\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom prophet import Prophet\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set font to support unicode minus sign\nplt.rcParams['axes.unicode_minus'] = False\n\nprint(\"ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æº–å‚™å®Œäº†ï¼\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\nif len(uploaded) == 0:\n    raise ValueError(\"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ä¸Šã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\")\n\nfilename = list(uploaded.keys())[0]\ndf = pd.read_csv(filename, encoding='utf-8')\n\nprint(f\"ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {df.shape}\")\nprint(f\"\\nåˆ—åä¸€è¦§:\")\nprint(df.columns.tolist())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ—åã®ç©ºç™½ã‚’å‰Šé™¤ï¼ˆå¿µã®ãŸã‚ï¼‰\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# æ—¥ä»˜ã‚’datetimeå‹ã«å¤‰æ›\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# MPã®å‰å‡¦ç†ï¼ˆã‚«ãƒ³ãƒã¨å¼•ç”¨ç¬¦ã‚’é™¤å»ã—ã¦æ•°å€¤ã«å¤‰æ›ï¼‰\n",
    "df['MP'] = df['MP'].astype(str).str.replace(',', '').str.replace('\"', '').str.strip()\n",
    "df['MP'] = pd.to_numeric(df['MP'], errors='coerce')\n",
    "\n",
    "print(\"ãƒ‡ãƒ¼ã‚¿ã®å…ˆé ­5è¡Œ:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPãŒå­˜åœ¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ï¼ˆè¨“ç·´ç”¨ï¼‰ã¨å­˜åœ¨ã—ãªã„ãƒ‡ãƒ¼ã‚¿ï¼ˆäºˆæ¸¬ç”¨ï¼‰ã‚’åˆ†é›¢\n",
    "df_train_full = df[df['MP'].notna()].copy()\n",
    "df_predict = df[df['MP'].isna()].copy()\n",
    "\n",
    "print(f\"è¨“ç·´ç”¨ãƒ‡ãƒ¼ã‚¿: {len(df_train_full)}è¡Œ ({df_train_full['date'].min()} ã€œ {df_train_full['date'].max()})\")\n",
    "print(f\"äºˆæ¸¬ç”¨ãƒ‡ãƒ¼ã‚¿: {len(df_predict)}è¡Œ ({df_predict['date'].min()} ã€œ {df_predict['date'].max()})\")\n",
    "\n",
    "# MP ã®åŸºæœ¬çµ±è¨ˆ\n",
    "print(f\"\\nMP ã®åŸºæœ¬çµ±è¨ˆ:\")\n",
    "print(f\"  å¹³å‡: {df_train_full['MP'].mean():,.0f}\")\n",
    "print(f\"  æ¨™æº–åå·®: {df_train_full['MP'].std():,.0f}\")\n",
    "print(f\"  æœ€å°: {df_train_full['MP'].min():,.0f}\")\n",
    "print(f\"  æœ€å¤§: {df_train_full['MP'].max():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ç‰¹å¾´é‡ã®æº–å‚™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç‰¹å¾´é‡ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹åˆ—ã‚’é¸æŠï¼ˆdate, day, MPä»¥å¤–ã®ãƒ€ãƒŸãƒ¼å¤‰æ•°åˆ—ï¼‰\n",
    "feature_cols = [col for col in df.columns if col not in ['date', 'day', 'MP']]\n",
    "\n",
    "print(f\"ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ ({len(feature_cols)}å€‹):\")\n",
    "print(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿½åŠ ã®ç‰¹å¾´é‡ã‚’ä½œæˆï¼ˆæ™‚ç³»åˆ—çš„ãªç‰¹å¾´ï¼‰\n",
    "def add_time_features(df):\n",
    "    df = df.copy()\n",
    "    df['day_of_year'] = df['date'].dt.dayofyear\n",
    "    df['week_of_year'] = df['date'].dt.isocalendar().week.astype(int)\n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "    \n",
    "    # å‘¨æœŸçš„ãªç‰¹å¾´ï¼ˆsin/coså¤‰æ›ï¼‰\n",
    "    df['day_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
    "    df['day_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
    "    df['week_sin'] = np.sin(2 * np.pi * df['week_of_year'] / 52)\n",
    "    df['week_cos'] = np.cos(2 * np.pi * df['week_of_year'] / 52)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_train_full = add_time_features(df_train_full)\n",
    "df_predict = add_time_features(df_predict)\n",
    "\n",
    "# æ›´æ–°ã•ã‚ŒãŸç‰¹å¾´é‡ãƒªã‚¹ãƒˆ\n",
    "feature_cols_extended = feature_cols + ['day_of_year', 'week_of_year', 'quarter', \n",
    "                                         'day_sin', 'day_cos', 'week_sin', 'week_cos']\n",
    "\n",
    "print(f\"\\næ‹¡å¼µç‰¹å¾´é‡ ({len(feature_cols_extended)}å€‹):\")\n",
    "print(feature_cols_extended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²\n",
    "\n",
    "æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ãªã®ã§ã€æœ€å¾Œã®ä¸€å®šæœŸé–“ã‚’ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ†ã‚¹ãƒˆæœŸé–“ã®è¨­å®šï¼ˆæœ€å¾Œã®6ãƒ¶æœˆï¼ç´„180æ—¥ï¼‰\n",
    "test_days = 180\n",
    "\n",
    "# æ™‚ç³»åˆ—é †ã«ã‚½ãƒ¼ãƒˆ\n",
    "df_train_full = df_train_full.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# åˆ†å‰²\n",
    "train_df = df_train_full.iloc[:-test_days].copy()\n",
    "test_df = df_train_full.iloc[-test_days:].copy()\n",
    "\n",
    "print(f\"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(train_df)}æ—¥ ({train_df['date'].min().date()} ã€œ {train_df['date'].max().date()})\")\n",
    "print(f\"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_df)}æ—¥ ({test_df['date'].min().date()} ã€œ {test_df['date'].max().date()})\")\n",
    "\n",
    "# ç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°ã®åˆ†é›¢\n",
    "X_train = train_df[feature_cols_extended]\n",
    "y_train = train_df['MP']\n",
    "X_test = test_df[feature_cols_extended]\n",
    "y_test = test_df['MP']\n",
    "\n",
    "print(f\"\\nX_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©ã¨å­¦ç¿’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'ãƒ¢ãƒ‡ãƒ«': model_name,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE(%)': mape,\n",
    "        'R2': r2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ã®è¾æ›¸\n",
    "models = {\n",
    "    '1. ç·šå½¢å›å¸°': LinearRegression(),\n",
    "    '2. Ridgeå›å¸°': Ridge(alpha=1.0),\n",
    "    '3. Lassoå›å¸°': Lasso(alpha=1.0),\n",
    "    '4. ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1),\n",
    "    '5. å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°': GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42),\n",
    "    '6. XGBoost': xgb.XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42),\n",
    "    '7. LightGBM': lgb.LGBMRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42, verbose=-1)\n",
    "}\n",
    "\n",
    "# çµæœã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ\n",
    "results = []\n",
    "predictions = {}\n",
    "\n",
    "print(\"ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¨è©•ä¾¡ã‚’é–‹å§‹...\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name} ã‚’å­¦ç¿’ä¸­...\")\n",
    "    \n",
    "    # å­¦ç¿’\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # äºˆæ¸¬\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions[name] = y_pred\n",
    "    \n",
    "    # è©•ä¾¡\n",
    "    result = evaluate_model(y_test, y_pred, name)\n",
    "    results.append(result)\n",
    "    \n",
    "    print(f\"  MAPE: {result['MAPE(%)']:.2f}%, R2: {result['R2']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"å…¨ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’å®Œäº†ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prophet ãƒ¢ãƒ‡ãƒ«ï¼ˆæ™‚ç³»åˆ—ç‰¹åŒ–ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n8. Prophet ã‚’å­¦ç¿’ä¸­...\")\n",
    "\n",
    "# Prophetç”¨ã®ãƒ‡ãƒ¼ã‚¿æº–å‚™\n",
    "prophet_train = train_df[['date', 'MP']].rename(columns={'date': 'ds', 'MP': 'y'})\n",
    "prophet_test = test_df[['date', 'MP']].rename(columns={'date': 'ds', 'MP': 'y'})\n",
    "\n",
    "# ç¥æ—¥ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ å¤‰æ•°ã¨ã—ã¦ä½¿ç”¨\n",
    "prophet_train['holiday_flg'] = train_df['holiday flg'].values\n",
    "\n",
    "# Prophetãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ\n",
    "prophet_model = Prophet(\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False,\n",
    "    seasonality_mode='multiplicative'\n",
    ")\n",
    "\n",
    "# è¿½åŠ ã®ãƒªã‚°ãƒ¬ãƒƒã‚µãƒ¼ã¨ã—ã¦ç¥æ—¥ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ \n",
    "prophet_model.add_regressor('holiday_flg')\n",
    "\n",
    "# å­¦ç¿’\n",
    "prophet_model.fit(prophet_train)\n",
    "\n",
    "# äºˆæ¸¬ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä½œæˆ\n",
    "future = prophet_test[['ds']].copy()\n",
    "future['holiday_flg'] = test_df['holiday flg'].values\n",
    "\n",
    "# äºˆæ¸¬\n",
    "prophet_forecast = prophet_model.predict(future)\n",
    "y_pred_prophet = prophet_forecast['yhat'].values\n",
    "predictions['8. Prophet'] = y_pred_prophet\n",
    "\n",
    "# è©•ä¾¡\n",
    "result_prophet = evaluate_model(y_test, y_pred_prophet, '8. Prophet')\n",
    "results.append(result_prophet)\n",
    "\n",
    "print(f\"  MAPE: {result_prophet['MAPE(%)']:.2f}%, R2: {result_prophet['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. çµæœã®æ¯”è¼ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµæœã‚’DataFrameã«å¤‰æ›\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# MAPEã§ã‚½ãƒ¼ãƒˆï¼ˆå°ã•ã„é †ï¼‰\n",
    "results_df = results_df.sort_values('MAPE(%)')\n",
    "\n",
    "# è¡¨ç¤ºç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ\n",
    "results_display = results_df.copy()\n",
    "results_display['MAE'] = results_display['MAE'].apply(lambda x: f\"{x:,.0f}\")\n",
    "results_display['RMSE'] = results_display['RMSE'].apply(lambda x: f\"{x:,.0f}\")\n",
    "results_display['MAPE(%)'] = results_display['MAPE(%)'].apply(lambda x: f\"{x:.2f}\")\n",
    "results_display['R2'] = results_display['R2'].apply(lambda x: f\"{x:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒçµæœï¼ˆMAPEé †ï¼‰\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nâ€» MAPEï¼ˆå¹³å‡çµ¶å¯¾ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆèª¤å·®ï¼‰ãŒå°ã•ã„ã»ã©ç²¾åº¦ãŒé«˜ã„\\n\")\n",
    "print(results_display.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å®š\n",
    "best_model_name = results_df.iloc[0]['ãƒ¢ãƒ‡ãƒ«']\n",
    "best_mape = results_df.iloc[0]['MAPE(%)']\n",
    "\n",
    "print(\"\\n\" + \"*\"*80)\n",
    "print(f\"ğŸ† æœ€ã‚‚ç²¾åº¦ãŒé«˜ã„ãƒ¢ãƒ‡ãƒ«: {best_model_name}\")\n",
    "print(f\"   MAPE: {best_mape:.2f}%\")\n",
    "print(\"*\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Accuracy comparison graphs\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# MAPE comparison\nax1 = axes[0]\ncolors = ['gold' if m == best_model_name else 'steelblue' for m in results_df['ãƒ¢ãƒ‡ãƒ«']]\nbars = ax1.barh(results_df['ãƒ¢ãƒ‡ãƒ«'], results_df['MAPE(%)'], color=colors)\nax1.set_xlabel('MAPE (%)', fontsize=12)\nax1.set_title('MAPE by Model (Lower is Better)', fontsize=14)\nax1.invert_yaxis()\nfor bar, val in zip(bars, results_df['MAPE(%)']):\n    ax1.text(val + 0.1, bar.get_y() + bar.get_height()/2, f'{val:.2f}%', va='center')\n\n# R2 comparison\nax2 = axes[1]\ncolors = ['gold' if m == best_model_name else 'steelblue' for m in results_df['ãƒ¢ãƒ‡ãƒ«']]\nbars = ax2.barh(results_df['ãƒ¢ãƒ‡ãƒ«'], results_df['R2'], color=colors)\nax2.set_xlabel('RÂ² Score', fontsize=12)\nax2.set_title('RÂ² by Model (Higher is Better)', fontsize=14)\nax2.invert_yaxis()\nfor bar, val in zip(bars, results_df['R2']):\n    ax2.text(val + 0.01, bar.get_y() + bar.get_height()/2, f'{val:.4f}', va='center')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. äºˆæ¸¬çµæœã®å¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize predictions from top 3 models\ntop_3_models = results_df.head(3)['ãƒ¢ãƒ‡ãƒ«'].tolist()\n\nfig, ax = plt.subplots(figsize=(14, 6))\n\n# Actual values\nax.plot(test_df['date'], y_test / 1_000_000, 'k-', label='Actual', linewidth=2, alpha=0.8)\n\n# Predictions from top 3 models\ncolors = ['red', 'blue', 'green']\nfor i, model_name in enumerate(top_3_models):\n    ax.plot(test_df['date'], predictions[model_name] / 1_000_000, \n            '--', color=colors[i], label=model_name, linewidth=1.5, alpha=0.7)\n\nax.set_title('Prediction vs Actual in Test Period (Top 3 Models)', fontsize=14)\nax.set_xlabel('Date')\nax.set_ylabel('MP (Million Yen)')\nax.legend(loc='upper left')\nax.grid(True, alpha=0.3)\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Detailed display of best model predictions\nfig, axes = plt.subplots(2, 1, figsize=(14, 10))\n\nbest_pred = predictions[best_model_name]\n\n# Top: Prediction vs Actual\nax1 = axes[0]\nax1.plot(test_df['date'], y_test / 1_000_000, 'b-', label='Actual', linewidth=2)\nax1.plot(test_df['date'], best_pred / 1_000_000, 'r--', label=f'{best_model_name} Prediction', linewidth=2)\nax1.fill_between(test_df['date'], y_test / 1_000_000, best_pred / 1_000_000, alpha=0.3, color='gray')\nax1.set_title(f'Best Model ({best_model_name}) - Prediction vs Actual', fontsize=14)\nax1.set_ylabel('MP (Million Yen)')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# Bottom: Prediction errors\nax2 = axes[1]\nerror_pct = (best_pred - y_test) / y_test * 100\ncolors = ['red' if e > 0 else 'blue' for e in error_pct]\nax2.bar(test_df['date'], error_pct, color=colors, alpha=0.7)\nax2.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\nax2.axhline(y=error_pct.mean(), color='green', linestyle='--', label=f'Mean Error: {error_pct.mean():.2f}%')\nax2.set_title('Daily Prediction Error (%)', fontsize=14)\nax2.set_ylabel('Error (%)')\nax2.set_xlabel('Date')\nax2.legend()\nax2.grid(True, alpha=0.3, axis='y')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ç‰¹å¾´é‡ã®é‡è¦åº¦ï¼ˆãƒ„ãƒªãƒ¼ç³»ãƒ¢ãƒ‡ãƒ«ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Display feature importance for LightGBM\nlgb_model = models['7. LightGBM']\n\n# Get feature importance\nimportance = pd.DataFrame({\n    'Feature': feature_cols_extended,\n    'Importance': lgb_model.feature_importances_\n}).sort_values('Importance', ascending=False)\n\n# Display top 15 features\nfig, ax = plt.subplots(figsize=(10, 8))\ntop_n = 15\nax.barh(importance.head(top_n)['Feature'], importance.head(top_n)['Importance'], color='steelblue')\nax.set_xlabel('Importance')\nax.set_title(f'Feature Importance (LightGBM, Top {top_n})', fontsize=14)\nax.invert_yaxis()\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nFeature Importance (Top 15):\")\nprint(importance.head(15).to_string(index=False))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. å°†æ¥äºˆæ¸¬ï¼ˆ2025-2026å¹´ï¼‰ã®å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å…¨è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã‚’å†å­¦ç¿’\n",
    "print(f\"æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ï¼ˆ{best_model_name}ï¼‰ã‚’å…¨ãƒ‡ãƒ¼ã‚¿ã§å†å­¦ç¿’...\")\n",
    "\n",
    "X_full = df_train_full[feature_cols_extended]\n",
    "y_full = df_train_full['MP']\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã®å†ä½œæˆã¨å­¦ç¿’\n",
    "if 'LightGBM' in best_model_name:\n",
    "    final_model = lgb.LGBMRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42, verbose=-1)\n",
    "elif 'XGBoost' in best_model_name:\n",
    "    final_model = xgb.XGBRegressor(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "elif 'ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ' in best_model_name:\n",
    "    final_model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "elif 'å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°' in best_model_name:\n",
    "    final_model = GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "elif 'Ridge' in best_model_name:\n",
    "    final_model = Ridge(alpha=1.0)\n",
    "elif 'Lasso' in best_model_name:\n",
    "    final_model = Lasso(alpha=1.0)\n",
    "else:\n",
    "    final_model = LinearRegression()\n",
    "\n",
    "final_model.fit(X_full, y_full)\n",
    "print(\"å†å­¦ç¿’å®Œäº†ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°†æ¥ãƒ‡ãƒ¼ã‚¿ã®äºˆæ¸¬\n",
    "if len(df_predict) > 0:\n",
    "    X_future = df_predict[feature_cols_extended]\n",
    "    future_predictions = final_model.predict(X_future)\n",
    "    \n",
    "    # çµæœã‚’DataFrameã«è¿½åŠ \n",
    "    df_predict['MP_äºˆæ¸¬'] = future_predictions\n",
    "    \n",
    "    print(\"\\nå°†æ¥äºˆæ¸¬çµæœï¼ˆæœˆåˆ¥é›†è¨ˆï¼‰:\")\n",
    "    df_predict['å¹´æœˆ'] = df_predict['date'].dt.to_period('M')\n",
    "    monthly_forecast = df_predict.groupby('å¹´æœˆ')['MP_äºˆæ¸¬'].sum().reset_index()\n",
    "    monthly_forecast['MP_äºˆæ¸¬ï¼ˆç™¾ä¸‡å††ï¼‰'] = (monthly_forecast['MP_äºˆæ¸¬'] / 1_000_000).round(1)\n",
    "    print(monthly_forecast[['å¹´æœˆ', 'MP_äºˆæ¸¬ï¼ˆç™¾ä¸‡å††ï¼‰']].to_string(index=False))\n",
    "    \n",
    "    print(f\"\\näºˆæ¸¬æœŸé–“åˆè¨ˆ: {df_predict['MP_äºˆæ¸¬'].sum() / 1_000_000:,.1f} ç™¾ä¸‡å††\")\n",
    "else:\n",
    "    print(\"äºˆæ¸¬å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize future predictions\nif len(df_predict) > 0:\n    fig, ax = plt.subplots(figsize=(14, 6))\n    \n    # Historical actual values\n    ax.plot(df_train_full['date'], df_train_full['MP'] / 1_000_000, 'b-', \n            label='Actual', linewidth=1, alpha=0.7)\n    \n    # Future predictions\n    ax.plot(df_predict['date'], df_predict['MP_äºˆæ¸¬'] / 1_000_000, 'r--', \n            label='Prediction', linewidth=1.5)\n    \n    # Boundary line\n    ax.axvline(x=df_train_full['date'].max(), color='gray', linestyle=':', alpha=0.7)\n    \n    ax.set_title('MP Forecast Result (Actual + Future Prediction)', fontsize=14)\n    ax.set_xlabel('Date')\n    ax.set_ylabel('MP (Million Yen)')\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. äºˆæ¸¬çµæœã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# äºˆæ¸¬çµæœã‚’CSVã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ\n",
    "if len(df_predict) > 0:\n",
    "    export_df = df_predict[['date', 'day', 'MP_äºˆæ¸¬']].copy()\n",
    "    export_df['MP_äºˆæ¸¬'] = export_df['MP_äºˆæ¸¬'].round(0).astype(int)\n",
    "    export_df.to_csv('mp_forecast_result.csv', index=False, encoding='utf-8-sig')\n",
    "    print(\"äºˆæ¸¬çµæœã‚’ 'mp_forecast_result.csv' ã«ä¿å­˜ã—ã¾ã—ãŸ\")\n",
    "    \n",
    "    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "    files.download('mp_forecast_result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. ã¾ã¨ã‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"åˆ†æã¾ã¨ã‚\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nã€ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ã€‘\")\n",
    "print(f\"  è¨“ç·´ãƒ‡ãƒ¼ã‚¿æœŸé–“: {df_train_full['date'].min().date()} ã€œ {df_train_full['date'].max().date()}\")\n",
    "print(f\"  äºˆæ¸¬å¯¾è±¡æœŸé–“: {df_predict['date'].min().date()} ã€œ {df_predict['date'].max().date()}\")\n",
    "\n",
    "print(\"\\nã€ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒçµæœï¼ˆMAPEé †ï¼‰ã€‘\")\n",
    "print(results_display.to_string(index=False))\n",
    "\n",
    "print(f\"\\nã€æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã€‘\")\n",
    "print(f\"  {best_model_name}\")\n",
    "print(f\"  MAPE: {best_mape:.2f}%\")\n",
    "\n",
    "print(\"\\nã€è€ƒå¯Ÿã€‘\")\n",
    "print(\"\"\"\n",
    "- ãƒ€ãƒŸãƒ¼å¤‰æ•°ï¼ˆå¹´ãƒ»æœˆãƒ»æ›œæ—¥ãƒ»ç¥æ—¥ï¼‰ã‚’ä½¿ã£ãŸç‰¹å¾´é‡ã¯æ—¥æ¬¡äºˆæ¸¬ã«æœ‰åŠ¹\n",
    "- å‘¨æœŸçš„ãªç‰¹å¾´ï¼ˆsin/coså¤‰æ›ï¼‰ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§å­£ç¯€æ€§ã‚’æ‰ãˆã‚„ã™ããªã‚‹\n",
    "- ãƒ„ãƒªãƒ¼ç³»ãƒ¢ãƒ‡ãƒ«ï¼ˆLightGBM, XGBoostç­‰ï¼‰ã¯ç‰¹å¾´é‡ã®éç·šå½¢é–¢ä¿‚ã‚’æ‰ãˆã‚„ã™ã„\n",
    "- Prophetã¯ç¥æ—¥åŠ¹æœã‚„å­£ç¯€æ€§ã‚’è‡ªå‹•ã§æ¤œå‡ºã™ã‚‹ãŒã€è©³ç´°ãªç‰¹å¾´é‡ãŒã‚ã‚‹å ´åˆã¯\n",
    "  ä»–ã®ãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒç²¾åº¦ãŒé«˜ããªã‚‹ã“ã¨ã‚‚ã‚ã‚‹\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}